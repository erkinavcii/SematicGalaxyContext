import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import plotly.express as px
from umap import UMAP
import os

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="My Semantic Brain", layout="wide")

# --- 1. MODELÄ° YÃœKLE ---
@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

model = load_model()

# --- 2. YARDIMCI FONKSÄ°YONLAR ---
def clean_tags(tag_input):
    """Tagleri temizler, sÄ±ralar ve duplicate'leri uÃ§urur."""
    tag_str = str(tag_input)
    if not tag_input or tag_str.strip() == "" or tag_str.lower() == "nan":
        return "genel"
    
    tags = [t.strip().lower() for t in tag_str.split(',')]
    tags = sorted(list(set(tags)))
    return ", ".join(tags)

def get_unique_tags(dataframe):
    """Dataframe iÃ§indeki tÃ¼m benzersiz etiketleri listeler (Sidebar iÃ§in)."""
    all_tags = set()
    if not dataframe.empty:
        for tags in dataframe['Tags'].fillna("").astype(str):
            # "ai, robot, tool" -> ["ai", "robot", "tool"]
            splitted = [t.strip() for t in tags.split(',')]
            all_tags.update(splitted)
    # BoÅŸ string varsa temizle ve sÄ±rala
    if "" in all_tags: all_tags.remove("")
    return sorted(list(all_tags))

# --- 3. VERÄ° YÃ–NETÄ°MÄ° ---
DATA_FILE = "data.csv"

def load_data():
    if not os.path.exists(DATA_FILE):
        # Ã–rnek veri seti
        data = {
            "Baslik": ["ElevenLabs", "Midjourney", "Notion AI", "ChatGPT", "Blender"],
            "Link": ["https://elevenlabs.io", "#", "#", "#", "#"],
            "Aciklama": [
                "Yapay zeka ile ses kopyalama ve metinden ses Ã¼retme aracÄ±.",
                "Metinden gÃ¶rsel oluÅŸturan yapay zeka sanat aracÄ±.",
                "Not alma uygulamasÄ± iÃ§inde yapay zeka asistanÄ±.",
                "Sohbet edebilen, kod yazan yapay zeka asistanÄ±.",
                "3 boyutlu modelleme ve animasyon programÄ±."
            ],
            "Tags": ["ai, ses, tool", "ai, gÃ¶rsel, sanat", "ai, ofis, not", "ai, chat, bot", "tasarÄ±m, 3d, modelleme"]
        }
        df = pd.DataFrame(data)
        df.to_csv(DATA_FILE, index=False)
    return pd.read_csv(DATA_FILE)

df = load_data()

# --- 4. VEKTÃ–R HESAPLAMA ---
def process_embeddings(dataframe):
    dataframe['Aciklama'] = dataframe['Aciklama'].fillna('')
    dataframe['Tags'] = dataframe['Tags'].fillna('')
    
    combined_text = dataframe['Aciklama'] + ". " + dataframe['Tags']
    embeddings = model.encode(combined_text.tolist())
    
    n_neighbors = min(15, len(dataframe) - 1) 
    if n_neighbors < 2: n_neighbors = 2
    
    umap_3d = UMAP(n_components=3, init='random', random_state=42, n_neighbors=n_neighbors)
    projections = umap_3d.fit_transform(embeddings)
    
    dataframe['x'] = projections[:, 0]
    dataframe['y'] = projections[:, 1]
    dataframe['z'] = projections[:, 2]
    return dataframe, embeddings

if not df.empty:
    df, embeddings = process_embeddings(df)
else:
    embeddings = np.array([])

# --- ARAYÃœZ ---
st.title("ðŸ§  My Semantic Brain")

# --- SIDEBAR (VERÄ° EKLEME & FÄ°LTRELEME) ---
with st.sidebar:
    # --- BÃ–LÃœM 1: FÄ°LTRELEME (YENÄ°) ---
    st.header("ðŸ·ï¸ Filtrele")
    unique_tags_list = get_unique_tags(df)
    selected_tags = st.multiselect(
        "Etiket SeÃ§ (Hybrid Search)", 
        unique_tags_list,
        placeholder="TÃ¼mÃ¼nÃ¼ GÃ¶ster"
    )
    
    st.divider() # Ã‡izgi Ã§ek

    # --- BÃ–LÃœM 2: EKLEME ---
    st.header("âž• Yeni Ä°Ã§erik Ekle")
    new_title = st.text_input("BaÅŸlÄ±k")
    new_link = st.text_input("Link")
    new_desc = st.text_area("AÃ§Ä±klama")
    raw_tags = st.text_input("Etiketler (ai, ses)")
    
    if st.button("Kaydet"):
        if new_title and new_desc: 
            final_tags = clean_tags(raw_tags)
            new_data = pd.DataFrame({
                "Baslik": [new_title], "Link": [new_link], 
                "Aciklama": [new_desc], "Tags": [final_tags]
            })
            new_data.to_csv(DATA_FILE, mode='a', header=False, index=False)
            st.success(f"Eklendi!")
            st.rerun() 
        else:
            st.warning("BaÅŸlÄ±k ve AÃ§Ä±klama zorunludur!")

# --- ANA FÄ°LTRELEME MANTIÄžI (GLOBAL) ---
# BurasÄ± uygulamanÄ±n kalbi. Arama veya Galaksi sekmelerine gitmeden Ã¶nce
# veriyi burada daraltÄ±yoruz.
filtered_df = df.copy()

# EÄŸer etiket seÃ§ildiyse DataFrame'i daralt
if selected_tags:
    # KRÄ°TÄ°K DÃœZELTME: ArtÄ±k hem "ai, robot" hem "ai,robot" formatlarÄ± destekleniyor.
    # split(',') ile ayÄ±rÄ±p strip() ile boÅŸluklarÄ± temizliyoruz.
    mask = filtered_df['Tags'].apply(
        lambda row_tags: any(
            tag in [t.strip() for t in str(row_tags).split(',')] 
            for tag in selected_tags
        )
    )
    filtered_df = filtered_df[mask]

# --- ANA EKRAN SEKMELERÄ° ---
tab1, tab2, tab3 = st.tabs(["ðŸ” Liste & Arama", "ðŸŒŒ Semantik Galaksi", "ðŸ› ï¸ Veri YÃ¶netimi"])

# --- TAB 1: HÄ°BRÄ°T ARAMA ---
with tab1:
    search_query = st.text_input("AkÄ±llÄ± Arama (Ã–rn: 'Ses yapan robotlar')", "")
    
    if not filtered_df.empty:
        display_df = filtered_df.copy() # FiltrelenmiÅŸ veri Ã¼zerinde Ã§alÄ±ÅŸacaÄŸÄ±z

        if search_query:
            # 1. Ã–nce tÃ¼m (orijinal) veri iÃ§in skorlarÄ± hesapla
            # (Ã‡Ã¼nkÃ¼ embeddings tÃ¼m veri iÃ§in var, indexler kaymasÄ±n)
            query_vec = model.encode([search_query])
            full_sim_scores = np.dot(embeddings, query_vec.T).flatten()
            
            # 2. SkorlarÄ± orijinal df'ye ekle
            df['Benzerlik'] = full_sim_scores
            
            # 3. Sonra filtrelenmiÅŸ df'ye bu skorlarÄ± map et (Merge/Join yerine loc ile alÄ±yoruz)
            display_df['Benzerlik'] = df.loc[display_df.index, 'Benzerlik']
            
            # 4. SÄ±rala
            display_df = display_df.sort_values(by='Benzerlik', ascending=False)
            st.write(f"**'{search_query}'** iÃ§in sonuÃ§lar ({len(display_df)} kayÄ±t):")
        else:
            # Arama yoksa ama filtre varsa
            if selected_tags:
                st.write(f"ðŸ·ï¸ **SeÃ§ili etiketlere gÃ¶re** sonuÃ§lar ({len(display_df)} kayÄ±t):")
            else:
                st.write("TÃ¼m kayÄ±tlar:")

        # SONUÃ‡LARI GÃ–STER (ORTAK ALAN)
        results = display_df.head(10) # Sayfada Ã§ok yÄ±ÄŸÄ±lma olmasÄ±n diye 10 tane
        
        if not results.empty:
            # Progress Bar Normalizasyonu
            if 'Benzerlik' in results.columns:
                min_score = results['Benzerlik'].min()
                max_score = results['Benzerlik'].max()
                denominator = max_score - min_score

            for index, row in results.iterrows():
                # Skor barÄ± sadece arama yapÄ±ldÄ±ysa anlamlÄ±dÄ±r
                if search_query and 'Benzerlik' in row:
                    score = row['Benzerlik']
                    if denominator == 0: normalized = score 
                    else: normalized = (score - min_score) / denominator
                    safe_progress = max(0.0, min(1.0, float(normalized)))
                    st.progress(safe_progress)
                    score_text = f"(Skor: {score:.2f})"
                else:
                    score_text = ""

                st.info(f"**{row['Baslik']}** {score_text} | ðŸ·ï¸ {row['Tags']}\n\n{row['Aciklama']}\n\n[ðŸ”— Git]({row['Link']})")
        else:
            st.warning("Bu kriterlere uygun sonuÃ§ bulunamadÄ±.")
            
    else:
        st.write("Veri yok veya filtreleme sonucu boÅŸ.")

# --- TAB 2: GÃ–RSELLEÅžTÄ°RME ---
with tab2:
    if not filtered_df.empty:
        # MesajÄ± duruma gÃ¶re deÄŸiÅŸtir
        if selected_tags:
            st.write(f"ðŸŒŒ Galaksi ÅŸu an **{', '.join(selected_tags)}** etiketlerine odaklandÄ±.")
        else:
            st.write("ðŸŒŒ Benzer aÃ§Ä±klamalar ve **benzer tagler** birbirini Ã§eker.")
            
        fig = px.scatter_3d(
            filtered_df, # DÄ°KKAT: ArtÄ±k filtrelenmiÅŸ datayÄ± Ã§iziyoruz!
            x='x', y='y', z='z',
            color='Tags', 
            hover_name='Baslik',
            hover_data={'Aciklama': True, 'Link': True, 'Tags': True, 'x': False, 'y': False, 'z': False},
            template="plotly_dark",
            opacity=0.9,
            size_max=15
        )
        fig.update_layout(
            scene=dict(xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False), bgcolor='rgba(0,0,0,0)'),
            margin=dict(l=0, r=0, b=0, t=10),
            legend=dict(yanchor="top", y=0.9, xanchor="left", x=0.1)
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.write("GÃ¶sterilecek veri yok.")

# --- TAB 3: VERÄ° YÃ–NETÄ°MÄ° ---
with tab3:
    st.header("Veri TabanÄ±nÄ± DÃ¼zenle")
    st.warning("âš ï¸ Dikkat: Burada yaptÄ±ÄŸÄ±nÄ±z deÄŸiÅŸiklikler 'DeÄŸiÅŸiklikleri Kaydet' butonuna basÄ±nca kalÄ±cÄ± olur.")
    
    if not df.empty:
        edited_df = st.data_editor(
            df[['Baslik', 'Link', 'Aciklama', 'Tags']], 
            num_rows="dynamic",
            use_container_width=True,
            key="data_editor"
        )
        
        if st.button("ðŸ’¾ DeÄŸiÅŸiklikleri Kaydet"):
            edited_df = edited_df.reset_index(drop=True)
            
            # Validation
            has_empty_title = edited_df['Baslik'].isnull().any() or (edited_df['Baslik'].astype(str).str.strip() == '').any()
            has_empty_desc = edited_df['Aciklama'].isnull().any() or (edited_df['Aciklama'].astype(str).str.strip() == '').any()

            if has_empty_title or has_empty_desc:
                st.error("âŒ Hata: 'Baslik' veya 'Aciklama' alanlarÄ± boÅŸ bÄ±rakÄ±lamaz!")
            else:
                # Normalizasyon
                edited_df['Tags'] = edited_df['Tags'].fillna("").astype(str).apply(clean_tags)
                
                # KayÄ±t
                edited_df.to_csv(DATA_FILE, index=False)
                st.success("âœ… Veri tabanÄ± gÃ¼ncellendi!")
                st.rerun()
    else:
        st.write("DÃ¼zenlenecek veri yok.")